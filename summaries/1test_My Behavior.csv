Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length
1000,1.4189383,0.0001998002,0.7923778,16.16449064016342,16.164491024566814,577.0
2000,1.4189383,0.00019940018,0.71853787,None,None,None
3000,1.4189383,0.00019900019,0.7248185,30.161965042352676,30.161965044710087,1439.0
4000,1.4189383,0.0001986002,0.74378735,10.808403100818396,10.808403288923728,816.0
5000,1.4189383,0.0001982002,0.75074697,17.199698014184833,17.199698224179883,706.0
6000,1.4189383,0.0001978002,0.7501347,12.903603351674974,12.903603200581813,692.5
7000,1.4189383,0.00019740018,0.9303874,5.487675368785858,5.487675610696897,227.0
