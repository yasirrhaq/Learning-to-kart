Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length
6000,1.3854834,0.00019999803,4.630858,228.47423821687698,228.474235098809,4922.0
7000,1.4315654,0.00019999803,4.535382,None,None,None
8000,1.4496541,0.00019999803,4.522917,None,None,None
9000,1.4447718,0.00019999803,4.525911,None,None,None
10000,1.4573092,0.00019999803,4.5114365,None,None,None
11000,1.3904568,0.00019999803,4.6186686,228.51278978586197,228.51278973557055,4922.0
12000,1.4433107,0.00019999803,4.5351224,None,None,None
13000,1.4481844,0.00019999803,4.5263286,None,None,None
14000,1.4921123,0.00019999802,4.525185,None,None,None
15000,1.4458314,0.000199998,4.523534,None,None,None
16000,1.4099498,0.000199998,4.628994,229.6059890985489,229.60598881356418,4922.0
17000,1.4437627,0.000199998,4.535533,None,None,None
