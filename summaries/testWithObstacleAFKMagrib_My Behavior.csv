Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length
1000,1.323817,0.00019999983,1.8573118,13.710149747133254,13.71014979227948,579.3
2000,1.3378825,0.00019999983,1.5506101,16.08254012465477,16.08254005127901,655.125
3000,1.3372484,0.00019999983,1.8100953,19.056891817312973,19.056891795374842,749.1538461538462
4000,1.3634318,0.00019999983,1.7970295,17.77589032866738,17.77589039059934,730.0909090909091
5000,1.3783221,0.00019999983,1.9948957,26.73227398097515,26.732273846563565,1001.0
6000,1.3777674,0.00019999983,2.1382082,16.43115649478776,16.43115642850762,565.8571428571429
7000,1.4347907,0.00019999976,2.2688375,34.325785368680954,34.3257852195793,1242.25
8000,1.4476279,0.00019999975,2.3667235,35.613198183476925,35.61319815571915,1249.125
9000,1.483484,0.00019999975,2.3662739,36.66610124281475,36.66610128334183,1272.7142857142858
10000,1.5031669,0.00019999972,2.4219265,35.79110377364688,35.79110362893617,1245.111111111111
11000,1.4876907,0.00019999972,2.4890952,20.74083437052156,20.740834348376147,696.0
12000,1.5056745,0.00019999972,2.487006,31.667554235458375,31.667554267730157,1071.8
13000,1.4957893,0.00019999972,2.5423615,32.43701898058256,32.43701879283253,1098.5
